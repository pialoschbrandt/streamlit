{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b19a4c",
   "metadata": {},
   "source": [
    "## Lenker til prosjektet\n",
    "\n",
    "- GitHub-repositorium: https://github.com/pialoschbrandt/streamlit#\n",
    "- Streamlit-app: https://appgit-2khm3anafqsdgqrdfpx7vz.streamlit.app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710b3b2c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a560106",
   "metadata": {},
   "source": [
    " ## 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4932b6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import date, timedelta\n",
    "import calendar\n",
    "import os\n",
    "import sys\n",
    "from pymongo.mongo_client import MongoClient    \n",
    "from pymongo.server_api import ServerApi\n",
    "import plotly.express as px\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce089c6",
   "metadata": {},
   "source": [
    "# 1.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a0739a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching January 2021 ... OK\n",
      "Fetching February 2021 ... OK\n",
      "Fetching March 2021 ... OK\n",
      "Fetching April 2021 ... OK\n",
      "Fetching May 2021 ... OK\n",
      "Fetching June 2021 ... OK\n",
      "Fetching July 2021 ... OK\n",
      "Fetching August 2021 ... OK\n",
      "Fetching September 2021 ... OK\n",
      "Fetching October 2021 ... OK\n",
      "Fetching November 2021 ... OK\n",
      "Fetching December 2021 ... OK\n",
      "Fetching January 2022 ... OK\n",
      "Fetching February 2022 ... OK\n",
      "Fetching March 2022 ... OK\n",
      "Fetching April 2022 ... OK\n",
      "Fetching May 2022 ... OK\n",
      "Fetching June 2022 ... OK\n",
      "Fetching July 2022 ... OK\n",
      "Fetching August 2022 ... OK\n",
      "Fetching September 2022 ... OK\n",
      "Fetching October 2022 ... OK\n",
      "Fetching November 2022 ... OK\n",
      "Fetching December 2022 ... OK\n",
      "Fetching January 2023 ... OK\n",
      "Fetching February 2023 ... OK\n",
      "Fetching March 2023 ... OK\n",
      "Fetching April 2023 ... OK\n",
      "Fetching May 2023 ... OK\n",
      "Fetching June 2023 ... OK\n",
      "Fetching July 2023 ... OK\n",
      "Fetching August 2023 ... OK\n",
      "Fetching September 2023 ... OK\n",
      "Fetching October 2023 ... OK\n",
      "Fetching November 2023 ... OK\n",
      "Fetching December 2023 ... OK\n",
      "Fetching January 2024 ... OK\n",
      "Fetching February 2024 ... OK\n",
      "Fetching March 2024 ... OK\n",
      "Fetching April 2024 ... OK\n",
      "Fetching May 2024 ... OK\n",
      "Fetching June 2024 ... OK\n",
      "Fetching July 2024 ... OK\n",
      "Fetching August 2024 ... OK\n",
      "Fetching September 2024 ... OK\n",
      "Fetching October 2024 ... OK\n",
      "Fetching November 2024 ... OK\n",
      "Fetching December 2024 ... OK\n",
      "\n",
      "Done fetching data.\n",
      "Total rows: 872953\n",
      "  country priceArea productionGroup  quantityKwh                  startTime  \\\n",
      "0      NO       NO1           hydro    2507716.8  2021-01-01T00:00:00+01:00   \n",
      "1      NO       NO1           hydro    2494728.0  2021-01-01T01:00:00+01:00   \n",
      "2      NO       NO1           hydro    2486777.5  2021-01-01T02:00:00+01:00   \n",
      "3      NO       NO1           hydro    2461176.0  2021-01-01T03:00:00+01:00   \n",
      "4      NO       NO1           hydro    2466969.2  2021-01-01T04:00:00+01:00   \n",
      "\n",
      "                     endTime            lastUpdatedTime  \n",
      "0  2021-01-01T01:00:00+01:00  2024-12-20T10:35:40+01:00  \n",
      "1  2021-01-01T02:00:00+01:00  2024-12-20T10:35:40+01:00  \n",
      "2  2021-01-01T03:00:00+01:00  2024-12-20T10:35:40+01:00  \n",
      "3  2021-01-01T04:00:00+01:00  2024-12-20T10:35:40+01:00  \n",
      "4  2021-01-01T05:00:00+01:00  2024-12-20T10:35:40+01:00  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "\n",
    "# URL for Elhub's energy data API\n",
    "base_url = \"https://api.elhub.no/energy-data/v0/price-areas\"\n",
    "\n",
    "# Parameters for the API request ‚Äì defines which dataset to fetch\n",
    "params = {'dataset': 'PRODUCTION_PER_GROUP_MBA_HOUR'}\n",
    "\n",
    "# List to collect all DataFrames\n",
    "all_data = []\n",
    "\n",
    "# Loop through all years 2021‚Äì2024\n",
    "for year in range(2021, 2025):\n",
    "    for month in range(1, 13):\n",
    "\n",
    "        # Start and end of month\n",
    "        start = date(year, month, 1)\n",
    "        end = date(year + 1, 1, 1) if month == 12 else date(year, month + 1, 1)\n",
    "\n",
    "        # Add timezone to match your original version\n",
    "        params['startDate'] = f\"{start.isoformat()}T00:00:00+02:00\"\n",
    "        params['endDate']   = f\"{end.isoformat()}T00:00:00+02:00\"\n",
    "\n",
    "        print(f\"Fetching {start.strftime('%B %Y')} ...\", end=\" \")\n",
    "\n",
    "        # API request\n",
    "        r = requests.get(base_url, params=params)\n",
    "        r.raise_for_status()\n",
    "\n",
    "        data = r.json().get('data', [])\n",
    "\n",
    "        # Build rows\n",
    "        rows = []\n",
    "        for d in data:\n",
    "            attr = d['attributes']\n",
    "            for p in attr['productionPerGroupMbaHour']:\n",
    "                rows.append({\n",
    "                    'country': attr.get('country'),\n",
    "                    'priceArea': p.get('priceArea'),\n",
    "                    'productionGroup': p.get('productionGroup'),\n",
    "                    'quantityKwh': p.get('quantityKwh'),\n",
    "                    'startTime': p.get('startTime'),\n",
    "                    'endTime': p.get('endTime'),\n",
    "                    'lastUpdatedTime': p.get('lastUpdatedTime')\n",
    "                })\n",
    "\n",
    "        if rows:\n",
    "            all_data.append(pd.DataFrame(rows))\n",
    "            print(\"OK\")\n",
    "        else:\n",
    "            print(\"EMPTY\")\n",
    "\n",
    "# Combine all data into one DataFrame\n",
    "df_all = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "print(\"\\nDone fetching data.\")\n",
    "print(\"Total rows:\", len(df_all))\n",
    "print(df_all.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1119142a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F√∏rste dato: 2020-12-31 23:00:00+00:00\n",
      "Siste dato: 2024-12-31 22:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "#Sjekker f√∏rste og siste dato i df_all for √• sjekka at alle √∏nskede datoer er med\n",
    "df_all[\"startTime\"] = pd.to_datetime(df_all[\"startTime\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "print(\"F√∏rste dato:\", df_all[\"startTime\"].min())\n",
    "print(\"Siste dato:\", df_all[\"startTime\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cd9f420e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021 2022 2023 2024]\n"
     ]
    }
   ],
   "source": [
    "#fjerner datoer fra 2020\n",
    "df_all[\"endTime\"] = pd.to_datetime(df_all[\"endTime\"], utc=True, errors=\"coerce\")\n",
    "df_all = df_all[df_all[\"endTime\"].dt.year >= 2021]\n",
    "print(df_all[\"endTime\"].dt.year.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ad1020ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 872953\n",
      "\n",
      "Column names in df_all:\n",
      "['country', 'priceArea', 'productionGroup', 'quantityKwh', 'startTime', 'endTime', 'lastUpdatedTime']\n",
      "\n",
      "Columns:\n",
      "- country\n",
      "- priceArea\n",
      "- productionGroup\n",
      "- quantityKwh\n",
      "- startTime\n",
      "- endTime\n",
      "- lastUpdatedTime\n"
     ]
    }
   ],
   "source": [
    "# Print the total number of rows in the DataFrame\n",
    "print(\"Number of rows:\", len(df_all))\n",
    "\n",
    "# ---- Get column names ----\n",
    "print(\"\\nColumn names in df_all:\")\n",
    "print(list(df_all.columns))\n",
    "\n",
    "# More readable with line breaks:\n",
    "print(\"\\nColumns:\")\n",
    "for col in df_all.columns:\n",
    "    print(\"-\", col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "893c3da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  price_area production_group                start_time  \\\n",
      "0        NO1            hydro 2020-12-31 23:00:00+00:00   \n",
      "1        NO1            hydro 2021-01-01 00:00:00+00:00   \n",
      "2        NO1            hydro 2021-01-01 01:00:00+00:00   \n",
      "3        NO1            hydro 2021-01-01 02:00:00+00:00   \n",
      "4        NO1            hydro 2021-01-01 03:00:00+00:00   \n",
      "\n",
      "                   end_time  quantity_kwh  \n",
      "0 2021-01-01 00:00:00+00:00     2507716.8  \n",
      "1 2021-01-01 01:00:00+00:00     2494728.0  \n",
      "2 2021-01-01 02:00:00+00:00     2486777.5  \n",
      "3 2021-01-01 03:00:00+00:00     2461176.0  \n",
      "4 2021-01-01 04:00:00+00:00     2466969.2  \n",
      "Columns after rename: ['price_area', 'production_group', 'start_time', 'end_time', 'quantity_kwh']\n"
     ]
    }
   ],
   "source": [
    "# Prepare the DataFrame before converting it\n",
    "# Keep only the relevant columns\n",
    "df_ready = df_all[[\"priceArea\", \"productionGroup\", \"startTime\", \"endTime\", \"quantityKwh\"]].copy()\n",
    "\n",
    "# Rename columns to snake_case\n",
    "df_ready.rename(columns={\n",
    "    \"priceArea\": \"price_area\",\n",
    "    \"productionGroup\": \"production_group\",\n",
    "    \"startTime\": \"start_time\",\n",
    "    \"endTime\": \"end_time\",\n",
    "    \"quantityKwh\": \"quantity_kwh\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Remove any rows missing key values\n",
    "df_ready.dropna(subset=[\"price_area\", \"start_time\"], inplace=True)\n",
    "\n",
    "# Convert time columns from string to datetime with UTC\n",
    "df_ready[\"start_time\"] = pd.to_datetime(df_ready[\"start_time\"], utc=True, errors=\"coerce\")\n",
    "df_ready[\"end_time\"] = pd.to_datetime(df_ready[\"end_time\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "print(df_ready.head())\n",
    "print(\"Columns after rename:\", list(df_ready.columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "60c58dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "USR, PWD = open('../no_sync/mongo_db.txt').read().splitlines()\n",
    "uri = f\"mongodb+srv://{USR}:{PWD}@cluster0.12mozyp.mongodb.net/\"\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cf617727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è  Slettet 0 dokumenter fra collectionen.\n"
     ]
    }
   ],
   "source": [
    "# Velg database og collection\n",
    "database = client['elhub_data']\n",
    "collection = database['production_per_group_mba_hour'] \n",
    "\n",
    "# ‚ùó Slett alle dokumenter i collection (men behold strukturen)\n",
    "delete_result = collection.delete_many({})\n",
    "print(f\"üóëÔ∏è  Slettet {delete_result.deleted_count} dokumenter fra collectionen.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2bc56847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Elhub-data er lastet opp til MongoDB (f√∏rste gang).\n"
     ]
    }
   ],
   "source": [
    "# Sjekk om collection allerede inneholder data\n",
    "existing_count = collection.count_documents({})\n",
    "\n",
    "if existing_count <= 1:\n",
    "    data = df_all.to_dict(\"records\")\n",
    "    collection.insert_many(df_ready.to_dict(\"records\"))\n",
    "    print(\"‚úÖ Elhub-data er lastet opp til MongoDB (f√∏rste gang).\")\n",
    "else:\n",
    "    print(f\"‚ÑπÔ∏è Collection inneholder allerede {existing_count} dokumenter ‚Äî hopper over opplasting.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ce3d700f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in 'production_per_group_mba_hour': 872953\n"
     ]
    }
   ],
   "source": [
    "# Select the database and collection\n",
    "database = client['elhub_data']\n",
    "collection = database['production_per_group_mba_hour']\n",
    "\n",
    "# Count the number of documents (rows)\n",
    "num_docs = collection.count_documents({})\n",
    "print(f\"Number of documents in 'production_per_group_mba_hour': {num_docs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06035d7",
   "metadata": {},
   "source": [
    "1.3 Push CONSUMPTION_PER_GROUP_MBA_HOUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ce6ca690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching consumption January 2021 ... OK\n",
      "Fetching consumption February 2021 ... OK\n",
      "Fetching consumption March 2021 ... OK\n",
      "Fetching consumption April 2021 ... OK\n",
      "Fetching consumption May 2021 ... OK\n",
      "Fetching consumption June 2021 ... OK\n",
      "Fetching consumption July 2021 ... OK\n",
      "Fetching consumption August 2021 ... OK\n",
      "Fetching consumption September 2021 ... OK\n",
      "Fetching consumption October 2021 ... OK\n",
      "Fetching consumption November 2021 ... OK\n",
      "Fetching consumption December 2021 ... OK\n",
      "Fetching consumption January 2022 ... OK\n",
      "Fetching consumption February 2022 ... OK\n",
      "Fetching consumption March 2022 ... OK\n",
      "Fetching consumption April 2022 ... OK\n",
      "Fetching consumption May 2022 ... OK\n",
      "Fetching consumption June 2022 ... OK\n",
      "Fetching consumption July 2022 ... OK\n",
      "Fetching consumption August 2022 ... OK\n",
      "Fetching consumption September 2022 ... OK\n",
      "Fetching consumption October 2022 ... OK\n",
      "Fetching consumption November 2022 ... OK\n",
      "Fetching consumption December 2022 ... OK\n",
      "Fetching consumption January 2023 ... OK\n",
      "Fetching consumption February 2023 ... OK\n",
      "Fetching consumption March 2023 ... OK\n",
      "Fetching consumption April 2023 ... OK\n",
      "Fetching consumption May 2023 ... OK\n",
      "Fetching consumption June 2023 ... OK\n",
      "Fetching consumption July 2023 ... OK\n",
      "Fetching consumption August 2023 ... OK\n",
      "Fetching consumption September 2023 ... OK\n",
      "Fetching consumption October 2023 ... OK\n",
      "Fetching consumption November 2023 ... OK\n",
      "Fetching consumption December 2023 ... OK\n",
      "Fetching consumption January 2024 ... OK\n",
      "Fetching consumption February 2024 ... OK\n",
      "Fetching consumption March 2024 ... OK\n",
      "Fetching consumption April 2024 ... OK\n",
      "Fetching consumption May 2024 ... OK\n",
      "Fetching consumption June 2024 ... OK\n",
      "Fetching consumption July 2024 ... OK\n",
      "Fetching consumption August 2024 ... OK\n",
      "Fetching consumption September 2024 ... OK\n",
      "Fetching consumption October 2024 ... OK\n",
      "Fetching consumption November 2024 ... OK\n",
      "Fetching consumption December 2024 ... OK\n",
      "\n",
      "Done fetching consumption data.\n",
      "Total rows: 876600\n",
      "  country priceArea consumptionGroup  quantityKwh                  startTime  \\\n",
      "0      NO       NO1            cabin    177071.56  2021-01-01T00:00:00+01:00   \n",
      "1      NO       NO1            cabin    171335.12  2021-01-01T01:00:00+01:00   \n",
      "2      NO       NO1            cabin    164912.02  2021-01-01T02:00:00+01:00   \n",
      "3      NO       NO1            cabin    160265.77  2021-01-01T03:00:00+01:00   \n",
      "4      NO       NO1            cabin    159828.69  2021-01-01T04:00:00+01:00   \n",
      "\n",
      "                     endTime            lastUpdatedTime  \n",
      "0  2021-01-01T01:00:00+01:00  2024-12-20T10:35:40+01:00  \n",
      "1  2021-01-01T02:00:00+01:00  2024-12-20T10:35:40+01:00  \n",
      "2  2021-01-01T03:00:00+01:00  2024-12-20T10:35:40+01:00  \n",
      "3  2021-01-01T04:00:00+01:00  2024-12-20T10:35:40+01:00  \n",
      "4  2021-01-01T05:00:00+01:00  2024-12-20T10:35:40+01:00  \n"
     ]
    }
   ],
   "source": [
    "# URL for Elhub API\n",
    "base_url = \"https://api.elhub.no/energy-data/v0/price-areas\"\n",
    "\n",
    "# Parameter: consumption dataset\n",
    "params = {'dataset': 'CONSUMPTION_PER_GROUP_MBA_HOUR'}\n",
    "\n",
    "# List for storing monthly DataFrames\n",
    "all_CONS = []\n",
    "\n",
    "# Loop through all years 2021‚Äì2024\n",
    "for year in range(2021, 2025):\n",
    "    for month in range(1, 13):\n",
    "\n",
    "        # Start and end of the month\n",
    "        start = date(year, month, 1)\n",
    "        end = date(year + 1, 1, 1) if month == 12 else date(year, month + 1, 1)\n",
    "\n",
    "        params[\"startDate\"] = f\"{start.isoformat()}T00:00:00+02:00\"\n",
    "        params[\"endDate\"]   = f\"{end.isoformat()}T00:00:00+02:00\"\n",
    "\n",
    "        print(f\"Fetching consumption {start.strftime('%B %Y')} ...\", end=\" \")\n",
    "\n",
    "        # API request\n",
    "        r = requests.get(base_url, params=params)\n",
    "        r.raise_for_status()\n",
    "\n",
    "        data_C = r.json().get(\"data\", [])\n",
    "\n",
    "        rows = []\n",
    "        for d in data_C:\n",
    "            attr = d[\"attributes\"]\n",
    "\n",
    "            # IMPORTANT: use consumptionPerGroupMbaHour\n",
    "            for p in attr[\"consumptionPerGroupMbaHour\"]:\n",
    "                rows.append({\n",
    "                    \"country\": attr.get(\"country\"),\n",
    "                    \"priceArea\": p.get(\"priceArea\"),\n",
    "                    \"consumptionGroup\": p.get(\"consumptionGroup\"),\n",
    "                    \"quantityKwh\": p.get(\"quantityKwh\"),\n",
    "                    \"startTime\": p.get(\"startTime\"),\n",
    "                    \"endTime\": p.get(\"endTime\"),\n",
    "                    \"lastUpdatedTime\": p.get(\"lastUpdatedTime\")\n",
    "                })\n",
    "\n",
    "        if rows:\n",
    "            all_CONS.append(pd.DataFrame(rows))\n",
    "            print(\"OK\")\n",
    "        else:\n",
    "            print(\"EMPTY\")\n",
    "\n",
    "# Combine all consumption data\n",
    "df_consumption = pd.concat(all_CONS, ignore_index=True)\n",
    "\n",
    "print(\"\\nDone fetching consumption data.\")\n",
    "print(\"Total rows:\", len(df_consumption))\n",
    "print(df_consumption.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "95a195ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F√∏rste dato: 2020-12-31 23:00:00+00:00\n",
      "Siste dato: 2024-12-31 22:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "#Sjekker f√∏rste og siste dato i df_all for √• sjekka at alle √∏nskede datoer er med\n",
    "df_consumption[\"startTime\"] = pd.to_datetime(df_consumption[\"startTime\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "print(\"F√∏rste dato:\", df_consumption[\"startTime\"].min())\n",
    "print(\"Siste dato:\", df_consumption[\"startTime\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d00135ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021 2022 2023 2024]\n"
     ]
    }
   ],
   "source": [
    "#fjerner datoer fra 2020\n",
    "df_consumption[\"endTime\"] = pd.to_datetime(df_consumption[\"endTime\"], utc=True, errors=\"coerce\")\n",
    "df_consumption = df_consumption[df_consumption[\"endTime\"].dt.year >= 2021]\n",
    "print(df_consumption[\"endTime\"].dt.year.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "04837864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['country', 'priceArea', 'consumptionGroup', 'quantityKwh', 'startTime',\n",
      "       'endTime', 'lastUpdatedTime'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_consumption.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "076d6899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country price_area consumption_group  quantity_kwh  \\\n",
      "0      NO        NO1             cabin     177071.56   \n",
      "1      NO        NO1             cabin     171335.12   \n",
      "2      NO        NO1             cabin     164912.02   \n",
      "3      NO        NO1             cabin     160265.77   \n",
      "4      NO        NO1             cabin     159828.69   \n",
      "\n",
      "                 start_time                  end_time  \\\n",
      "0 2020-12-31 23:00:00+00:00 2021-01-01 00:00:00+00:00   \n",
      "1 2021-01-01 00:00:00+00:00 2021-01-01 01:00:00+00:00   \n",
      "2 2021-01-01 01:00:00+00:00 2021-01-01 02:00:00+00:00   \n",
      "3 2021-01-01 02:00:00+00:00 2021-01-01 03:00:00+00:00   \n",
      "4 2021-01-01 03:00:00+00:00 2021-01-01 04:00:00+00:00   \n",
      "\n",
      "          last_updated_time  \n",
      "0 2024-12-20 09:35:40+00:00  \n",
      "1 2024-12-20 09:35:40+00:00  \n",
      "2 2024-12-20 09:35:40+00:00  \n",
      "3 2024-12-20 09:35:40+00:00  \n",
      "4 2024-12-20 09:35:40+00:00  \n",
      "Columns after cleaning: ['country', 'price_area', 'consumption_group', 'quantity_kwh', 'start_time', 'end_time', 'last_updated_time']\n",
      "Total rows after cleaning: 876600\n"
     ]
    }
   ],
   "source": [
    "# Extract only the columns that actually exist\n",
    "df_cons_ready = df_consumption[[\n",
    "    \"country\",\n",
    "    \"priceArea\",\n",
    "    \"consumptionGroup\",\n",
    "    \"quantityKwh\",\n",
    "    \"startTime\",\n",
    "    \"endTime\",\n",
    "    \"lastUpdatedTime\"\n",
    "]].copy()\n",
    "\n",
    "# Rename to snake_case for consistency\n",
    "df_cons_ready.rename(columns={\n",
    "    \"country\": \"country\",\n",
    "    \"priceArea\": \"price_area\",\n",
    "    \"consumptionGroup\": \"consumption_group\",\n",
    "    \"quantityKwh\": \"quantity_kwh\",\n",
    "    \"startTime\": \"start_time\",\n",
    "    \"endTime\": \"end_time\",\n",
    "    \"lastUpdatedTime\": \"last_updated_time\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Drop rows missing essential values\n",
    "df_cons_ready.dropna(subset=[\"price_area\", \"start_time\"], inplace=True)\n",
    "\n",
    "# Convert time columns to proper datetime format with UTC\n",
    "df_cons_ready[\"start_time\"] = pd.to_datetime(df_cons_ready[\"start_time\"], utc=True, errors=\"coerce\")\n",
    "df_cons_ready[\"end_time\"]   = pd.to_datetime(df_cons_ready[\"end_time\"],   utc=True, errors=\"coerce\")\n",
    "df_cons_ready[\"last_updated_time\"] = pd.to_datetime(df_cons_ready[\"last_updated_time\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "print(df_cons_ready.head())\n",
    "print(\"Columns after cleaning:\", list(df_cons_ready.columns))\n",
    "print(\"Total rows after cleaning:\", len(df_cons_ready))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "247c8ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Slettet 0 dokumenter fra collectionen.\n",
      "‚úÖ Lastet opp 876600 konsum-dokumenter!\n"
     ]
    }
   ],
   "source": [
    "# 1) Velg database og COLLECTION for konsum\n",
    "database = client['elhub_data']\n",
    "collection = database['consumption_per_group_mba_hour']\n",
    "\n",
    "# 2) T√∏m collection hvis den finnes\n",
    "delete_result = collection.delete_many({})\n",
    "print(f\"üßπ Slettet {delete_result.deleted_count} dokumenter fra collectionen.\")\n",
    "\n",
    "# 3) Sjekk om collection er tom og last opp\n",
    "existing_count = collection.count_documents({})\n",
    "\n",
    "if existing_count == 0:\n",
    "    collection.insert_many(df_cons_ready.to_dict(\"records\"))\n",
    "    print(f\"‚úÖ Lastet opp {len(df_cons_ready)} konsum-dokumenter!\")\n",
    "else:\n",
    "    print(f\"‚ÑπÔ∏è Collection inneholder allerede {existing_count} dokumenter ‚Äî hopper over opplasting.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6b0f8b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in 'consumption_per_group_mba_hour': 876600\n"
     ]
    }
   ],
   "source": [
    "# Select the database and collection\n",
    "database = client['elhub_data']\n",
    "collection = database['consumption_per_group_mba_hour']\n",
    "\n",
    "# Count the number of documents (rows)\n",
    "num_doc = collection.count_documents({})\n",
    "print(f\"Number of documents in 'consumption_per_group_mba_hour': {num_doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c64336c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PRODUCTION SAMPLE ---\n",
      "{'_id': ObjectId('691b681c3de029eec9c00245'),\n",
      " 'end_time': datetime.datetime(2021, 1, 1, 6, 0),\n",
      " 'price_area': 'NO1',\n",
      " 'production_group': 'hydro',\n",
      " 'quantity_kwh': 2482320.8,\n",
      " 'start_time': datetime.datetime(2021, 1, 1, 5, 0)}\n",
      "\n",
      "--- CONSUMPTION SAMPLE ---\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pprint\n",
    "\n",
    "user = \"user_1234\"\n",
    "password = \"user_1234\"\n",
    "cluster = \"cluster0.12mozyp.mongodb.net\"\n",
    "\n",
    "uri = f\"mongodb+srv://{user}:{password}@{cluster}/?retryWrites=true&w=majority\"\n",
    "client = pymongo.MongoClient(uri)\n",
    "\n",
    "db = client[\"elhub_data\"]\n",
    "\n",
    "print(\"\\n--- PRODUCTION SAMPLE ---\")\n",
    "pprint.pprint(db[\"production_per_group_mba_hour\"].find_one())\n",
    "\n",
    "print(\"\\n--- CONSUMPTION SAMPLE ---\")\n",
    "pprint.pprint(db[\"consumption_per_group_hour\"].find_one())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4b3442",
   "metadata": {},
   "source": [
    "## 2.1 GeoJSON from NVE Elspot omr√•der"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b15b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "12404ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolonner i GeoJSON:\n",
      "Index(['OBJECTID', 'ElSpotOmr', 'GlobalID', 'Shape_Length', 'Shape_Area',\n",
      "       'geometry'],\n",
      "      dtype='object')\n",
      "\n",
      "F√∏rste rad:\n",
      "   OBJECTID ElSpotOmr GlobalID  Shape_Length    Shape_Area  \\\n",
      "0         6      NO 2     None  1.256473e+06  6.875969e+10   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((5.74061 60.3517, 5.73955 60.35362, 5...  \n"
     ]
    }
   ],
   "source": [
    "#Sjekker hva som ligger i kolonnene i filen\n",
    "import geopandas as gpd\n",
    "areas = gpd.read_file(\"/Users/pialoschbrandt/Documents/Skole/Semester-5/Ind320/Innlevering1/file.geojson\")\n",
    "\n",
    "\n",
    "print(\"Kolonner i GeoJSON:\")\n",
    "print(areas.columns)\n",
    "\n",
    "print(\"\\nF√∏rste rad:\")\n",
    "print(areas.head(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a38b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rense kolonnene\n",
    "\n",
    "areas[\"ElSpotOmr\"] = areas[\"ElSpotOmr\"].str.replace(\" \", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "afd88691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "   OBJECTID ElSpotOmr GlobalID  Shape_Length    Shape_Area  \\\n",
      "0         6       NO2     None  1.256473e+06  6.875969e+10   \n",
      "1         7       NO5     None  1.106762e+06  3.334870e+10   \n",
      "2         8       NO1     None  1.657761e+06  6.052902e+10   \n",
      "3         9       NO3     None  1.773323e+06  1.042199e+11   \n",
      "4        10       NO4     None  3.385499e+06  2.032500e+11   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((5.74061 60.3517, 5.73955 60.35362, 5...  \n",
      "1  POLYGON ((7.41477 61.85483, 7.4125 61.85751, 7...  \n",
      "2  POLYGON ((11.80905 62.8288, 11.80786 62.82916,...  \n",
      "3  POLYGON ((10.87378 65.41986, 10.57806 65.47018...  \n",
      "4  POLYGON ((28.33596 71.29423, 28.31789 71.29557...  \n",
      "Index(['OBJECTID', 'ElSpotOmr', 'GlobalID', 'Shape_Length', 'Shape_Area',\n",
      "       'geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(type(areas))\n",
    "print(areas.head())\n",
    "print(areas.columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (streamlit)",
   "language": "python",
   "name": "streamlit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
